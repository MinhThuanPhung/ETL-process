# -*- coding: utf-8 -*-
"""ETL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fSO7df579Eab8HHmTcn70dbhwzczK7Gk

# **HR Analytics: Job Change of Data Scientists**

# **Extract data**
"""

import pandas as pd
import numpy as np

# enrollies_data = pd.read_excel('/content/Enrollies.xlsx')

url='https://docs.google.com/spreadsheets/d/1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI/export?format=xlsx'
enrollies_data = pd.read_excel(url, sheet_name='enrollies')

enrollies_data.info()

enrollies_data.gender.unique()

# enrollies_education = pd.read_excel('/content/enrollies_education.xlsx')
# mỗi lần chạy lại code lại phải upload file nên up lên github

enrollies_education = pd.read_csv('https://raw.githubusercontent.com/MinhThuanPhung/ETL-process/refs/heads/main/enrollies_education.csv')

# enrollies_working_experience = pd.read_csv('/content/work_experience.csv')
enrollies_working_experience = pd.read_csv('https://raw.githubusercontent.com/MinhThuanPhung/ETL-process/refs/heads/main/work_experience.csv')

from sqlalchemy import create_engine
!pip install pymysql

!pip install sqlalchemy

import pymysql

user_name = 'etl_practice'
password = '550814'
host = '112.213.86.31'
port = 3360
database = 'company_course'
engine = create_engine('mysql+pymysql://{0}:{1}@{2}:{3}/{4}'.format(user_name, password, host, port, database)

engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')

training_hours = pd.read_sql_table('training_hours', con=engine)
# cách 2 : training_hours =  pd.read_sql('SELECT * FROM training_hours', con=engine)

city_development_index = pd.read_html("https://sca-programming-school.github.io/city_development_index/index.html")[0]

employment = pd.read_sql_table('employment', con=engine)

employment.info()

city_development_index.info()

training_hours.info()

enrollies_working_experience.info()

enrollies_education.info()

enrollies_data.info()

"""# **Transform data**

**enrollies_data**
"""

# clean enrollies_data

# fill null value for gender
enrollies_data.gender = enrollies_data.gender.fillna("Unknown")
# convert data type
enrollies_data = enrollies_data.convert_dtypes()

enrollies_data.gender.unique()

enrollies_data.info()

"""**enrollies_education**"""

# clean enrollies_education

enrollies_education.info()

enrollies_education.head()

# fill null by mode
object_col = enrollies_education.select_dtypes(include='object').columns
enrollies_education[object_col] = enrollies_education[object_col].fillna(enrollies_education.mode().iloc[0])

# chuyển về mode TH dữ liệu Null khoảng tầm dưới 10%, nếu trên 10% consider Unknown hoặc check lại với các bên liên quan
#consitency data
  # capitalize all characters for major discipline
enrollies_education.major_discipline = enrollies_education.major_discipline.str.upper()
  # replace _ in enroll university by space
enrollies_education.enrolled_university= enrollies_education.enrolled_university.str.replace('_', '  ', regex=False)
  # capitalize the first character in errolled university column
enrollies_education.enrolled_university = enrollies_education.enrolled_university.str.capitalize()

# convert data type
enrollies_education = enrollies_education.convert_dtypes()

enrollies_education.major_discipline.unique()

enrollies_education.head()

enrollies_education.duplicated().sum()

"""**enrollies_working_experience**"""

# fill in the null value for enrollies_working_experience and convert type

enrollies_working_experience.head()

enrollies_working_experience.info()

# fill null
object_col = enrollies_working_experience.select_dtypes(include='object').columns
enrollies_working_experience[object_col] = enrollies_working_experience[object_col].fillna(enrollies_working_experience.mode().iloc[0])

# convert data type
enrollies_working_experience = enrollies_working_experience.convert_dtypes()

enrollies_working_experience.info()

"""**city_development_index**"""

city_development_index = city_development_index.convert_dtypes()

city_development_index.info()

"""**Other dataframes do not have null value and duplicate**

# **Load data in data warehouse**
"""

db_name = "errollee_datawarehouse.db"

#[enrollies_data,enrollies_education, enrollies_working_experience,training_hours,city_development_index,employment]

engine = create_engine(f'sqlite:///{db_name}')
enrollies_data.to_sql('enrollies_data', engine, if_exists='replace')
enrollies_working_experience.to_sql('enrollies_working_experience', engine, if_exists='replace')
training_hours.to_sql('training_hours', engine, if_exists='replace')
enrollies_education.to_sql('enrollies_education', engine, if_exists='replace')
city_development_index.to_sql('city_development_index', engine, if_exists='replace')
employment.to_sql('employment', engine, if_exists='replace')

"""**Hướng dẫn từ buổi lý thuyết**"""

# Create an engine object to connect to the database
# warehouse_engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')

# Write DataFrames to database

#enrollies_data.to_sql('Fact_EnrolliesData', con=warehouse_engine, if_exists='replace', index=False)
# enrollies_working_experience.to_sql('Dim_EnrolliesWorkingExperience', con=warehouse_engine, if_exists='replace', index=False)
# training_hours.to_sql('Dim_TrainingHours', con=warehouse_engine, if_exists='replace', index=False)
 # enrollies_education.to_sql('Dim_EnrolliesEducation', con=warehouse_engine, if_exists='replace', index=False)
# city_development_index.to_sql('Dim_CityDevelopmentIndex', con=warehouse_engine, if_exists='replace', index=False)
# employment.to_sql('Dim_Employment', con=warehouse_engine, if_exists='replace', index=False)